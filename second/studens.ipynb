{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: DROP OUT CLASSIFIER\n",
    "(by: Martin Marsal, Benedikt Allmendinger, Christian Diegmann; Heilbronn University, Germany, November 2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "- Nullen raus (braucht nochmal Diskussionsbedarf, Nullen werden bei manchen Features nämlich gebraucht)\n",
    "- Long floats kürzen auf 2te kommastelle (done)\n",
    "- Normalisieren von Daten? Daruch wird training schneller, ohne Zusammenhangsverlust\n",
    "- Biased Features raus? nö, alle wichtig\n",
    "- Ausreißer raus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert csv file to a pandas DataFrame\n",
    "df = pd.read_csv('student_data.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Rounding to two decimal places\n",
    "df['Curricular units 2nd sem (grade)'] = df['Curricular units 2nd sem (grade)'].round(2)\n",
    "\n",
    "# Mapping the target values to level of risk:\n",
    "df['Target'] = df['Target'].map({'Dropout': 2, 'Enrolled': 1, 'Graduate': 0})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise how the features correlate with each other\n",
    "Calculate and visualise how the features correlate with each other and with the labels. Pick an interesting correlation\n",
    "and discuss it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a figure and axis\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use imshow to display the correlation matrix\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='none')\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels for rows and columns\n",
    "plt.xticks(np.arange(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(np.arange(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "\n",
    "# Add title\n",
    "plt.title('Feature Correlation Matrix')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Flatten the matrix to sort and identify the highest correlations\n",
    "correlation_pairs = correlation_matrix.unstack()\n",
    "sorted_pairs = correlation_pairs.sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Display top 10 correlations (excluding self-correlation at 1.0)\n",
    "print(\"Top 10 Correlations\")\n",
    "print(sorted_pairs.drop_duplicates().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Curricular units (credited, enrolled, approved) from the first and second semesters tend to have a strong correlation. This is logical, as an individual's performance and workload are generally consistent across semesters.  \n",
    "\n",
    "Similarly, the occupations of the mother and father show a notable correlation.  \n",
    "\n",
    "There is also a strong correlation between nationality and being classified as \"international.\" This can be explained by the fact that international students typically have a different nationality than non-international students, while non-international students are usually of the same nationality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame and reset the index\n",
    "shuffle_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the size of the training set (80% of the data)\n",
    "train_size = int(0.8 * len(shuffle_df))\n",
    "\n",
    "# Split the DataFrame into training and test sets\n",
    "train_df = shuffle_df.iloc[:train_size]\n",
    "test_df = shuffle_df.iloc[train_size:]\n",
    "\n",
    "# Print the training and test sets\n",
    "print(train_df)\n",
    "print(test_df)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Combine training and test sets for consistent encoding\n",
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "combined_df = pd.get_dummies(combined_df, columns=categorical_cols)\n",
    "\n",
    "# Split back into training and test sets\n",
    "train_df = combined_df.iloc[:len(train_df), :]\n",
    "test_df = combined_df.iloc[len(train_df):, :]\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('Target', axis=1) # replace real with targets\n",
    "y_train = train_df['Target']\n",
    "X_test = test_df.drop('Target', axis=1)\n",
    "y_test = test_df['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train at least four machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_probabilistic = nb_clf.predict(X_test)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_probabilistic = cross_val_score(nb_clf, X_train, y_train, cv=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 tree based - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model with a random state for reproducibility\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "\n",
    "# Initialize the model with hyperparameters\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=10)\n",
    "\n",
    "# Retrain the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_tree = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 distance-based  - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define a range of k values to test\n",
    "k_values = range(1, 51)  # Test k values from 1 to 50\n",
    "accuracies = []\n",
    "\n",
    "# Loop through different k values to find the best one\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)  # Train with the current k\n",
    "    y_pred = knn.predict(X_test)  # Predict on the test set\n",
    "    acc = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    accuracies.append(acc)  # Store the accuracy for each k\n",
    "\n",
    "# Find the k with the highest accuracy\n",
    "best_k = k_values[accuracies.index(max(accuracies))]\n",
    "print(f\"The best k value is: {best_k} with accuracy of {max(accuracies) * 100:.2f}%\")\n",
    "\n",
    "# Plot k vs accuracy\n",
    "\n",
    "plt.plot(k_values, accuracies, marker='o')\n",
    "plt.xlabel(\"k (Number of Neighbors)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for Different k Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 3. Initialize the k-NN classifier\n",
    "k = 7  # Choose the number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# 4. Perform k-fold cross-validation\n",
    "cv_scores_distance_based = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "# 5. Train the k-NN Classifier on the entire training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred_distance_based = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Ensemble method - C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Are all models equally well suited for this task? Discuss your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluate the four models using k-fold cross validation and give at least accuracy (mean and standard deviation) and\n",
    "confusion matrix for the trained models. Is one of the models significantly better than the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(scores, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plots a box plot for cross-validation scores.\n",
    "    \n",
    "    Parameters:\n",
    "    - scores (list or array): Cross-validation scores to visualize.\n",
    "    - model_name (str): Name of the model (for labeling purposes).\n",
    "    \"\"\"\n",
    "        \n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean CV score: {scores.mean():.2f}\")\n",
    "    plt.boxplot(scores, vert=False, patch_artist=True)\n",
    "    plt.title(f\"Cross-Validation Scores ({model_name})\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.yticks([1], [model_name])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (array-like): Ground truth (correct) target values.\n",
    "    - y_pred (array-like): Estimated targets as returned by a classifier.\n",
    "    - labels (list, optional): Class labels to display on the axes.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.matshow(conf_matrix, cmap=\"Blues\", alpha=0.6)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', color=\"black\")\n",
    "    \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    if labels:\n",
    "        ax.set_xticks(np.arange(len(labels)))\n",
    "        ax.set_yticks(np.arange(len(labels)))\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set_yticklabels(labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(cv_scores_probabilistic, model_name=\"Random Forest\")\n",
    "plot_confusion_matrix(y_test, y_pred_probabilistic, labels=[\"Class 0\", \"Class 1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 tree based - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(cv_scores_tree, model_name=\"DecisionTreeClassifier\")\n",
    "plot_confusion_matrix(y_test, y_pred_tree, labels=[\"Class 0\", \"Class 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 distance-based  - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(cv_scores_distance_based, model_name=\"KNeighborsClassifier\")\n",
    "plot_confusion_matrix(y_test, y_pred_distance_based, labels=[\"Class 0\", \"Class 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Ensemble method - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "\n",
    "# plot_boxplot(cv_scores_ensemble_method, model_name=\"Random Forest\")\n",
    "# plot_confusion_matrix(y_test, y_pred_ensemble_method, labels=[\"Class 0\", \"Class 1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick your favorite model. \n",
    "Which features were most relevant for the for the students’ success?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your favorite model as pickle-file with https://scikit-learn.org/stable/model_persistence.html. Call the file “best_model.pkl”.\n",
    "\n",
    "\n",
    "The submission consists of two files:\n",
    "1. A Jupyter Notebook containing the preprocessing, the training, and the evaluation of\n",
    "your models.\n",
    "2. A pickle-file “best_model.pkl”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
