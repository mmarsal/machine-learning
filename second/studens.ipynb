{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: DROP OUT CLASSIFIER\n",
    "(by: Martin Marsal, Benedikt Allmendinger, Christian Diegmann; Heilbronn University, Germany, November 2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "- Nullen raus (braucht nochmal Diskussionsbedarf, Nullen werden bei manchen Features nämlich gebraucht)\n",
    "- Long floats kürzen auf 2te kommastelle (done)\n",
    "- Normalisieren von Daten? Daruch wird training schneller, ohne Zusammenhangsverlust\n",
    "- Biased Features raus? nö, alle wichtig\n",
    "- Ausreißer raus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert csv file to a pandas DataFrame\n",
    "df = pd.read_csv('student_data.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Rounding to two decimal places\n",
    "df['Curricular units 2nd sem (grade)'] = df['Curricular units 2nd sem (grade)'].round(2)\n",
    "\n",
    "# Mapping the target values to level of risk:\n",
    "df['Target'] = df['Target'].map({'Dropout': 2, 'Enrolled': 1, 'Graduate': 0})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the DataFrame and reset the index\n",
    "shuffle_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the size of the training set (80% of the data)\n",
    "train_size = int(0.8 * len(shuffle_df))\n",
    "\n",
    "# Split the DataFrame into training and test sets\n",
    "train_df = shuffle_df.iloc[:train_size]\n",
    "test_df = shuffle_df.iloc[train_size:]\n",
    "\n",
    "# Print the training and test sets\n",
    "print(train_df)\n",
    "print(test_df)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Combine training and test sets for consistent encoding\n",
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "combined_df = pd.get_dummies(combined_df, columns=categorical_cols)\n",
    "\n",
    "# Split back into training and test sets\n",
    "train_df = combined_df.iloc[:len(train_df), :]\n",
    "test_df = combined_df.iloc[len(train_df):, :]\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('Target', axis=1) # replace real with targets\n",
    "y_train = train_df['Target']\n",
    "X_test = test_df.drop('Target', axis=1)\n",
    "y_test = test_df['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train at least four machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 tree based - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model with a random state for reproducibility\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Generate confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Initialize the model with hyperparameters\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=10)\n",
    "\n",
    "# Retrain the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {cv_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 distance-based  - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a range of k values to test\n",
    "k_values = range(1, 51)  # Test k values from 1 to 50\n",
    "accuracies = []\n",
    "\n",
    "# Loop through different k values to find the best one\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)  # Train with the current k\n",
    "    y_pred = knn.predict(X_test)  # Predict on the test set\n",
    "    acc = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    accuracies.append(acc)  # Store the accuracy for each k\n",
    "\n",
    "# Find the k with the highest accuracy\n",
    "best_k = k_values[accuracies.index(max(accuracies))]\n",
    "print(f\"The best k value is: {best_k} with accuracy of {max(accuracies) * 100:.2f}%\")\n",
    "\n",
    "# Plot k vs accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(k_values, accuracies, marker='o')\n",
    "plt.xlabel(\"k (Number of Neighbors)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for Different k Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 3. Initialize the k-NN classifier\n",
    "k = 7  # Choose the number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# 4. Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "# Output cross-validation results\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation accuracy: {np.mean(cv_scores) * 100:.2f}%\")\n",
    "print(f\"Standard deviation of cross-validation accuracy: {np.std(cv_scores) * 100:.2f}%\")\n",
    "\n",
    "# 5. Train the k-NN Classifier on the entire training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# 7. Evaluate the Model on the Test Set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Plot Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.matshow(conf_matrix, cmap=\"Blues\", alpha=0.6)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', color=\"black\")\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Ensemble method - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Are all models equally well suited for this task? Discuss your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluate the four models using k-fold cross validation and give at least accuracy (mean and standard deviation) and\n",
    "confusion matrix for the trained models. Is one of the models significantly better than the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 tree based - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 distance-based  - M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Ensemble method - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick your favorite model. \n",
    "Which features were most relevant for the for the students’ success?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your favorite model as pickle-file with https://scikit-learn.org/stable/model_persistence.html. Call the file “best_model.pkl”.\n",
    "\n",
    "\n",
    "The submission consists of two files:\n",
    "1. A Jupyter Notebook containing the preprocessing, the training, and the evaluation of\n",
    "your models.\n",
    "2. A pickle-file “best_model.pkl”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
