{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: DROP OUT CLASSIFIER\n",
    "(by: Martin Marsal, Benedikt Allmendinger, Christian Diegmann; Heilbronn University, Germany, November 2024)\n",
    "\n",
    "This project implements and evaluates four different models to classify how likely it is for a student to drop out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "\n",
    "- Normalisieren von Daten? Dadurch wird training schneller, ohne Zusammenhangsverlust\n",
    "- Biased Features raus? nö, alle wichtig\n",
    "- Ausreißer raus"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert csv file to a pandas DataFrame\n",
    "df = pd.read_csv('student_data.csv')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "foundNull = df.isnull().values.any()\n",
    "\n",
    "if foundNull:\n",
    "    raise TypeError('Found null value in DataFrame.')\n",
    "\n",
    "# Rounding to two decimal places\n",
    "df['Curricular units 2nd sem (grade)'] = df['Curricular units 2nd sem (grade)'].round(2)\n",
    "\n",
    "# Mapping the target values to level of risk:\n",
    "df['Target'] = df['Target'].map({'Dropout': 2, 'Enrolled': 1, 'Graduate': 0})\n",
    "\n",
    "# Create array with feature names for feature relevancy later\n",
    "feature_names = df.columns\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise how the features correlate with each other\n",
    "Calculate and visualise how the features correlate with each other and with the labels. Pick an interesting correlation\n",
    "and discuss it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a figure and axis\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use imshow to display the correlation matrix\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='none')\n",
    "\n",
    "# Add colorbar\n",
    "plt.colorbar()\n",
    "\n",
    "# Add labels for rows and columns\n",
    "plt.xticks(np.arange(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(np.arange(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "\n",
    "# Add title\n",
    "plt.title('Feature Correlation Matrix')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Flatten the matrix to sort and identify the highest correlations\n",
    "correlation_pairs = correlation_matrix.unstack()\n",
    "sorted_pairs = correlation_pairs.sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Display top 10 correlations (excluding self-correlation at 1.0)\n",
    "print(\"Top 10 Correlations\")\n",
    "print(sorted_pairs.drop_duplicates().head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Curricular units (credited, enrolled, approved) from the first and second semesters tend to have a strong correlation. This is logical, as an individual's performance and workload are generally consistent across semesters.  \n",
    "\n",
    "Similarly, the occupations of the mother and father show a notable correlation.  \n",
    "\n",
    "There is also a strong correlation between nationality and being classified as \"international.\" This can be explained by the fact that international students typically have a different nationality than non-international students, while non-international students are usually of the same nationality.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Shuffle the DataFrame and reset the index\n",
    "shuffle_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the size of the training set (80% of the data)\n",
    "train_size = int(0.8 * len(shuffle_df))\n",
    "\n",
    "# Split the DataFrame into training and test sets\n",
    "train_df = shuffle_df.iloc[:train_size]\n",
    "test_df = shuffle_df.iloc[train_size:]\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = train_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Combine training and test sets for consistent encoding\n",
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "combined_df = pd.get_dummies(combined_df, columns=categorical_cols)\n",
    "\n",
    "# Split back into training and test sets\n",
    "train_df = combined_df.iloc[:len(train_df), :]\n",
    "test_df = combined_df.iloc[len(train_df):, :]\n",
    "\n",
    "# Separate features and target\n",
    "X_train = train_df.drop('Target', axis=1)\n",
    "y_train = train_df['Target']\n",
    "X_test = test_df.drop('Target', axis=1)\n",
    "y_test = test_df['Target']\n",
    "\n",
    "# Scale the data for K-Nearest Neighbors\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Scaled training set\n",
    "X_test_scaled = scaler.transform(X_test)       # Scaled test set\n",
    "\n",
    "# Output results\n",
    "print(\"Unscaled Training Features:\")\n",
    "print(X_train)\n",
    "print(\"Scaled Training Features (for KNN):\")\n",
    "print(X_train_scaled)\n",
    "print(\"Unscaled Test Features:\")\n",
    "print(X_test)\n",
    "print(\"Scaled Test Features (for KNN):\")\n",
    "print(X_test_scaled)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train at least four machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importing the Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_probabilistic = nb_clf.predict(X_test)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_probabilistic = cross_val_score(nb_clf, X_train, y_train, cv=5)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 tree based - B"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model with a random state for reproducibility\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "\n",
    "# Initialize the model with hyperparameters\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=10)\n",
    "\n",
    "# Retrain the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_tree = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 distance-based  - M"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define a range of k values to test\n",
    "k_values = range(1, 51)  # Test k values from 1 to 50\n",
    "accuracies = []\n",
    "\n",
    "# Loop through different k values to find the best one\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)  # Train with the current k\n",
    "    y_pred = knn.predict(X_test_scaled)  # Predict on the test set\n",
    "    acc = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    accuracies.append(acc)  # Store the accuracy for each k\n",
    "\n",
    "# Find the k with the highest accuracy\n",
    "best_k = k_values[accuracies.index(max(accuracies))]\n",
    "print(f\"The best k value is: {best_k} with accuracy of {max(accuracies) * 100:.2f}%\")\n",
    "\n",
    "# Plot k vs accuracy\n",
    "\n",
    "plt.plot(k_values, accuracies, marker='o')\n",
    "plt.xlabel(\"k (Number of Neighbors)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy for Different k Values\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 3. Initialize the k-NN classifier\n",
    "k = best_k  # Choose the number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# 4. Perform k-fold cross-validation\n",
    "cv_scores_distance_based = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "# 5. Train the k-NN Classifier on the entire training set\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred_distance_based = knn.predict(X_test_scaled)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Ensemble method - C\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Step 1: Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # 100 trees in the forest\n",
    "\n",
    "# Step 2: Fit the model (using the entire training set)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Perform k-fold cross-validation (let's use k=10)\n",
    "k = 10\n",
    "cv_scores_random_forest = cross_val_score(rf_model, X_train, y_train, cv=k)\n",
    "\n",
    "# Mean and standard deviation of accuracy\n",
    "mean_accuracy = cv_scores_random_forest.mean()\n",
    "std_accuracy = cv_scores_random_forest.std()\n",
    "\n",
    "# Step 4: Generate predictions and evaluate the confusion matrix\n",
    "y_pred = cross_val_predict(rf_model, X_train, y_train, cv=k)\n",
    "conf_matrix = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Random Forest Accuracy (mean): {mean_accuracy:.4f}\")\n",
    "print(f\"Random Forest Accuracy (std): {std_accuracy:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "# Test set performance\n",
    "y_test_pred_random_forest = rf_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_random_forest)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Are all models equally well suited for this task? Discuss your conclusion."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Code Cell"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluate the four models using k-fold cross validation and give at least accuracy (mean and standard deviation) and\n",
    "confusion matrix for the trained models. Is one of the models significantly better than the others?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_boxplot(scores, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plots a box plot for cross-validation scores.\n",
    "    \n",
    "    Parameters:\n",
    "    - scores (list or array): Cross-validation scores to visualize.\n",
    "    - model_name (str): Name of the model (for labeling purposes).\n",
    "    \"\"\"\n",
    "        \n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean CV score: {scores.mean():.2f}\")\n",
    "    plt.boxplot(scores, vert=False, patch_artist=True)\n",
    "    plt.title(f\"Cross-Validation Scores ({model_name})\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.yticks([1], [model_name])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels=None):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true (array-like): Ground truth (correct) target values.\n",
    "    - y_pred (array-like): Estimated targets as returned by a classifier.\n",
    "    - labels (list, optional): Class labels to display on the axes.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.matshow(conf_matrix, cmap=\"Blues\", alpha=0.6)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', color=\"black\")\n",
    "    \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    if labels:\n",
    "        ax.set_xticks(np.arange(len(labels)))\n",
    "        ax.set_yticks(np.arange(len(labels)))\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set_yticklabels(labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_boxplot(cv_scores_probabilistic, model_name=\"Random Forest\")\n",
    "plot_confusion_matrix(y_test, y_pred_probabilistic, labels=[\"Class 0\", \"Class 1\"])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 tree based - B"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_boxplot(cv_scores_tree, model_name=\"DecisionTreeClassifier\")\n",
    "plot_confusion_matrix(y_test, y_pred_tree, labels=[\"Class 0\", \"Class 1\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 distance-based  - M"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_boxplot(cv_scores_distance_based, model_name=\"KNeighborsClassifier\")\n",
    "plot_confusion_matrix(y_test, y_pred_distance_based, labels=[\"Class 0\", \"Class 1\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 Ensemble method - C"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_boxplot(cv_scores_random_forest, model_name=\"Random Forest\")\n",
    "plot_confusion_matrix(y_test, y_test_pred_random_forest, labels=[\"Class 0\", \"Class 1\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "According to the confusion matrices, all the four models are very good at predicting which students are likely to graduate and also quite good at who's likely to drop out. However, they still have trouble to make predictions for class 1, so students who are at a moderate danger of dropping out. This is probably due to the fact that there's no clear line from when students should be put into class 0 or 2."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick your favorite model. \n",
    "Which features were most relevant for the for the students’ success?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We pick the random forest (ensemble method) as our best model since it did the best in our evaluation, in particular measured by the accuracy."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Combine feature names and their importances into a single array\n",
    "features_with_importances = np.array(list(zip(feature_names, feature_importances)))\n",
    "\n",
    "# Sort by importance (descending order)\n",
    "sorted_features = sorted(features_with_importances, key=lambda x: float(x[1]), reverse=True)\n",
    "\n",
    "# Get the top 5 features\n",
    "top_5_features = sorted_features[:5]\n",
    "\n",
    "# Display the top 5 features\n",
    "print(\"Top 5 Relevant Features:\")\n",
    "for feature, importance in top_5_features:\n",
    "    print(f\"{feature}: {importance}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "With its built-in feature importance we learn that the following features are the most relevant for the students' success: Curricular units 2nd sem (approved), Curricular units 2nd sem (grade), Curricular units 1st sem (approved), Curricular units 1st sem (grade) and Admission grade.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your favorite model as pickle-file with https://scikit-learn.org/stable/model_persistence.html. Call the file “best_model.pkl”.\n",
    "\n",
    "\n",
    "The submission consists of two files:\n",
    "1. A Jupyter Notebook containing the preprocessing, the training, and the evaluation of\n",
    "your models.\n",
    "2. A pickle-file “best_model.pkl”"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a pickle file\n",
    "with open('best_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
