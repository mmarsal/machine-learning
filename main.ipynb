{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0049fdb5",
   "metadata": {},
   "source": [
    "# Project 1: Naive Bayes Classifier\n",
    "(by: Martin Marsal, Benedikt Allmendinger, Christian Diegmann; Heilbronn University, Germany, October 2024) \n",
    "\n",
    "In this notebook we will implement the Naive Bayes and use it for a data set to determine the patients' degree of sickness.\n",
    "\n",
    "For this project the following sources were used:\n",
    "\n",
    "To get a theoretical understanding, we used the following videos:\n",
    "\n",
    "https://youtu.be/O2L2Uv9pdDA?si=Npoky40k9q39SRwG (Naive Bayes, Clearly Explained!!! by StatQuest with Josh Starmer)\n",
    "\n",
    "https://youtu.be/rzFX5NWojp0?si=V3a0dzutb8p5CWdL (The Normal Distribution, Clearly Explained!!! by StatQuest with Josh Starmer)\n",
    "\n",
    "https://youtu.be/H3EjCKtlVog?si=aUJhf6edHaAKJRRq (Gaussian Naive Bayes, Clearly Explained!!! by StatQuest with Josh Starmer)\n",
    "\n",
    "For the coding part it was a combination of the following:\n",
    "\n",
    "https://chatgpt.com/ (ChatGPT)\n",
    "\n",
    "https://pandas.pydata.org/docs/ (Pandas Package Documentation)\n",
    "\n",
    "https://docs.python.org/3/library/math.html (Math Package Documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94dadde",
   "metadata": {},
   "source": [
    "### Import Naive Bayes Classifier implementation"
   ]
  },
  {
   "cell_type": "code",
   "id": "64868c6a",
   "metadata": {},
   "source": [
    "from naive_bayes_classifier import *\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a302a41a",
   "metadata": {},
   "source": [
    "### Convert CSV File to a Pandas DataFrame\n",
    "\n",
    "In this step, we load a CSV file into a Pandas DataFrame using the `pd.read_csv()` function. We specify the delimiter as a semicolon (`;`) since the CSV file is separated by semicolons. After loading the data, we strip any leading or trailing whitespace from the column names using the `str.strip()` method to ensure clean headers. Finally, we print the DataFrame to verify the contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fdbf0ca8934a0c24",
   "metadata": {},
   "source": [
    "# Convert csv file to a pandas DataFrame\n",
    "df = pd.read_csv('inflammation_diagnosis.csv', sep=';')\n",
    "\n",
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e82ad2a",
   "metadata": {},
   "source": [
    "### Create 'continuous' Array\n",
    "\n",
    "In this step, we generate a `continuous` array that indicates whether each column in the DataFrame contains continuous or discrete values. We iterate over every column in the DataFrame, excluding the label column, and check the first value of each column. If the value is 'yes' or 'no', we treat it as a discrete column, and append `False` to the `continuous` array. Otherwise, we assume the column contains continuous data and append `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6da92879",
   "metadata": {},
   "source": [
    "# Initialize the 'continuous' array\n",
    "continuous = []\n",
    "\n",
    "# Iterate over every column except the label column\n",
    "for column in df.columns[:-1]:  \n",
    "    first_value = df[column].iloc[0]\n",
    "    \n",
    "    # Check if the first value is discrete (yes/no)\n",
    "    if first_value == 'yes' or first_value == 'no':\n",
    "        continuous.append(False)\n",
    "    else:  # Otherwise, it's continuous\n",
    "        continuous.append(True)\n",
    "        \n",
    "# Print the 'continuous' array\n",
    "print(continuous)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4e3d55e",
   "metadata": {},
   "source": [
    "#### Different approach for the creation of 'continuous' array to be more generalised"
   ]
  },
  {
   "cell_type": "code",
   "id": "26875704",
   "metadata": {},
   "source": [
    "# Set a threshold for unique values. If a column has fewer than x unique values, itâ€™s likely discrete\n",
    "unique_value_threshold = 10\n",
    "\n",
    "# Determine if each column is continuous or discrete\n",
    "continuous = []\n",
    "for column in df.columns[:-1]:  # Exclude the label column\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        # Check the number of unique values for numeric columns\n",
    "        unique_values = df[column].nunique()\n",
    "        if unique_values < unique_value_threshold:\n",
    "            continuous.append(False)  # Treat as discrete if unique values are below threshold\n",
    "        else:\n",
    "            continuous.append(True)   # Treat as continuous\n",
    "    else:\n",
    "        # Non-numeric columns are considered discrete\n",
    "        continuous.append(False)\n",
    "        \n",
    "print(continuous)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6fff289b",
   "metadata": {},
   "source": [
    "### Plot the CSV"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3b1c81d",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify categorical columns dynamically (in this case, 'inflammation' and 'nephritis')\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a figure dynamically for each categorical feature\n",
    "fig, axes = plt.subplots(1, len(categorical_columns), figsize=(5 * len(categorical_columns), 6))\n",
    "\n",
    "# If there's only one categorical column, we need to ensure 'axes' is treated as a list\n",
    "if len(categorical_columns) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Iterate over each categorical column and plot the distribution\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    # Get the value counts for each class in the column\n",
    "    value_counts = df[column].value_counts()\n",
    "    \n",
    "    # Plot the data\n",
    "    axes[i].bar(value_counts.index, value_counts.values, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {column.capitalize()}')\n",
    "    axes[i].set_xlabel(column.capitalize())\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b935dbf5",
   "metadata": {},
   "source": [
    "### Instantiate the NaiveBayes Class\n",
    "\n",
    "In this step, we instantiate the `NaiveBayes` class, which will be used to perform classification. The constructor takes in the `continuous` array, which specifies which features in the dataset are continuous or discrete. This information is essential for the Naive Bayes classifier to handle the different types of data appropriately.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "08d3b130",
   "metadata": {},
   "source": [
    "# Instantiate the NaiveBayes class, passing the continuous array\n",
    "naive_bayes = NaiveBayes(continuous)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "819db6d3",
   "metadata": {},
   "source": [
    "### Create 'disease' Column and Drop Unnecessary Columns\n",
    "\n",
    "We begin by mapping the values of the 'inflammation' and 'nephritis' columns from 'yes'/'no' to `True`/`False`. Then, we define a function `classify_disease()` that categorizes each row into 'very sick', 'sick', or 'healthy' based on the values of 'inflammation' and 'nephritis'. This function is applied to each row of the DataFrame to create a new 'disease' column.\n",
    "\n",
    "Afterward, the original 'inflammation' and 'nephritis' columns are dropped, leaving us with the 'disease' column. Finally, the 'disease' column is also dropped to create a `df_complete` DataFrame, which is printed at the end."
   ]
  },
  {
   "cell_type": "code",
   "id": "61c811186c661a6e",
   "metadata": {},
   "source": [
    "# Map 'yes'/'no' to True/False for inflammation and nephritis columns\n",
    "df['inflammation'] = df['inflammation'].map({'yes': True, 'no': False})\n",
    "df['nephritis'] = df['nephritis'].map({'yes': True, 'no': False})\n",
    "\n",
    "# Apply classification function to each row\n",
    "df['disease'] = df.apply(naive_bayes.classify_disease, axis=1)\n",
    "\n",
    "# Drop the 'inflammation' and 'nephritis' columns\n",
    "df = df.drop(columns=['inflammation', 'nephritis'])\n",
    "\n",
    "df_complete = df\n",
    "\n",
    "# Create the df_complete by dropping the 'disease' column as well\n",
    "df_complete = df.drop(columns=['disease'])\n",
    "\n",
    "# Print the final DataFrame\n",
    "print(df_complete)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50539ef1",
   "metadata": {},
   "source": [
    "### Plot the updated Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "edfcb2f3",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Identify categorical columns dynamically (in this case, 'inflammation' and 'nephritis')\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a figure dynamically for each categorical feature\n",
    "fig, axes = plt.subplots(1, len(categorical_columns), figsize=(5 * len(categorical_columns), 6))\n",
    "\n",
    "# If there's only one categorical column, we need to ensure 'axes' is treated as a list\n",
    "if len(categorical_columns) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Iterate over each categorical column and plot the distribution\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    # Get the value counts for each class in the column\n",
    "    value_counts = df[column].value_counts()\n",
    "    \n",
    "    # Plot the data\n",
    "    axes[i].bar(value_counts.index, value_counts.values, color='skyblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribution of {column.capitalize()}')\n",
    "    axes[i].set_xlabel(column.capitalize())\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "386e9850",
   "metadata": {},
   "source": [
    "### Randomize DataFrame and Split into Train and Test Sets\n",
    "\n",
    "In this step, we shuffle the DataFrame using the `sample()` method with a fraction of `1` to randomize the entire dataset. We set the `random_state` to ensure reproducibility of the shuffle. After shuffling, the DataFrame is split into an 80% training set and a 20% test set. The training set is extracted from the first 80% of the shuffled DataFrame, and the test set is from the remaining 20%. Both sets are then printed to verify the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "614a221df778bc0e",
   "metadata": {},
   "source": [
    "# Shuffle the DataFrame and reset the index\n",
    "shuffle_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the size of the training set (80% of the data)\n",
    "train_size = int(0.8 * len(shuffle_df))\n",
    "\n",
    "# Split the DataFrame into training and test sets\n",
    "train_df = shuffle_df.iloc[:train_size]\n",
    "test_df = shuffle_df.iloc[train_size:]\n",
    "\n",
    "# Print the training and test sets\n",
    "print(train_df)\n",
    "print(test_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7aeda7d",
   "metadata": {},
   "source": [
    "# Calculate the percentage of unique samples in test data and check for identical rows by index\n",
    "percentage_unique_test, has_identical_rows = naive_bayes.check_data_difference(train_df, test_df)\n",
    "\n",
    "print(f\"Percentage of unique samples in test data compared to training data: {percentage_unique_test}%\")\n",
    "print(has_identical_rows)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9c7f7c27",
   "metadata": {},
   "source": [
    "### Fit the NaiveBayes Classifier to the Training Data\n",
    "\n",
    "We now fit the `NaiveBayes` classifier to the training dataset. The `fit()` method takes the training DataFrame (`train_df`) and the target column name (`\"disease\"`), which contains the labels we are trying to predict. This step trains the model by learning the underlying patterns and relationships between the features and the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "674c4bcd0cb1100d",
   "metadata": {},
   "source": [
    "# Define the target column name\n",
    "target_name = \"disease\"\n",
    "\n",
    "# Fit the NaiveBayes classifier on the training data\n",
    "naive_bayes.fit(train_df, target_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "265c6ddaed1afa93",
   "metadata": {},
   "source": [
    "print(naive_bayes.priors)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91ad0d004937cdb3",
   "metadata": {},
   "source": [
    "print(naive_bayes.likelihoods)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c729dd57d99e9c72",
   "metadata": {},
   "source": [
    "print(naive_bayes.gaussian_parameters)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a5c10a83",
   "metadata": {},
   "source": [
    "### Predict Probabilities with NaiveBayes Classifier\n",
    "\n",
    "After fitting the model, we can use the `predict_probability()` method to estimate the probability distribution of the target variable for each instance in the dataset. Here, we pass the `df_complete` DataFrame (which contains the features but not the target column) to the method to generate these probability predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d3731ec37465d38f",
   "metadata": {},
   "source": [
    "# Predict the probabilities for each instance in df_complete\n",
    "naive_bayes.predict_probability(df_complete)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29729c29",
   "metadata": {},
   "source": [
    "### Separate the Last Column and Evaluate the NaiveBayes Classifier\n",
    "\n",
    "In this step, we separate the last column of the test set into two parts: `test_data`, which contains the feature columns, and `test_labels`, which contains the true labels for the test set. We then evaluate the performance of the NaiveBayes classifier using the `evaluate_on_data()` method. This method compares the modelâ€™s predictions to the actual labels in the test set and provides an evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "id": "305ca3ba23d13bce",
   "metadata": {},
   "source": [
    "# Separate the features and labels in the test set\n",
    "test_data = test_df.iloc[:, :-1]  # All columns except the last\n",
    "test_labels = test_df.iloc[:, -1]  # The last column (target)\n",
    "\n",
    "# Evaluate the NaiveBayes classifier and store the accuracy\n",
    "accuracy, confusion_matrix = naive_bayes.evaluate_on_data(test_data, test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy of the NaiveBayes classifier: {accuracy * 100:.2f}%\")\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "# Convert the confusion matrix to a numpy array\n",
    "confusion_matrix = np.array(confusion_matrix)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "disp.plot(ax=ax, cmap=\"Blues\")\n",
    "\n",
    "# Adding the title and accuracy annotation\n",
    "ax.set_title(f\"Confusion Matrix\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6613f0fd",
   "metadata": {},
   "source": [
    "### Visualize Data with Matplotlib\n",
    "\n",
    "To gain more insight into the data, we will visualize it using `matplotlib`. We will create a bar plot that shows the distribution of the predicted disease categories for the test data. This visualization will help us understand how the classifier's predictions are distributed across the different disease classes."
   ]
  },
  {
   "cell_type": "code",
   "id": "4b925e84",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Use predict_probability to get predictions and probabilities\n",
    "results = naive_bayes.predict_probability(test_data)\n",
    "\n",
    "# Extract the predicted labels from the 'Prediction' column\n",
    "predicted_labels = results['Prediction']\n",
    "\n",
    "# Count the occurrences of each unique label in the predicted labels\n",
    "unique_labels, counts = np.unique(predicted_labels, return_counts=True)\n",
    "\n",
    "# Create a bar chart to visualize the distribution of predicted labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(unique_labels, counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Distribution of Predicted Disease Labels', fontsize=16)\n",
    "plt.xlabel('Disease Category', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
