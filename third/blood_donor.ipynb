{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Project 3: Blood Donor Classification\n",
    "(by: Martin Marsal, Benedikt Allmendinger, Christian Diegmann; Heilbronn University, Germany, January 2025)\n",
    "\n",
    "This project implements a machine learning pipeline that helps hospital staff to decide whether a\n",
    "person can be a blood donor.\n",
    "\n",
    "The following references were used:\n",
    "\n",
    "Some of the lectures from \"Machine Learning (172336)\"\n",
    "\n",
    "https://chatgpt.com/ (ChatGPT)"
   ],
   "id": "715e29004ced62fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 0. Preperation\n",
    "First, get to know the dataset and deal with missing values.\n",
    "- Perform an exploratory data analysis to get to know the data set\n",
    "- Preprocess the data. If there are missing values, impute them.\n",
    "- Estimate the accuracy of your imputation for each feature"
   ],
   "id": "1a786bcb66498cdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "id": "f1e5e2d5bbacb547",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('hemodat.csv')\n",
    "\n",
    "# 1. Basic Information\n",
    "print(\"Basic Information:\")\n",
    "print(df.info())\n",
    "print(\"\\nShape of the dataset:\", df.shape)"
   ],
   "id": "1c1586fc9b0d3799",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. Summary Statistics\n",
    "print(\"\\nSummary Statistics (Numerical):\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nSummary Statistics (Categorical):\")\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(df[categorical_columns].describe())"
   ],
   "id": "6a8bf9db324cd42c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3. Distribution Analysis\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Histograms for numerical data\n",
    "df[numerical_columns].hist(bins=15, figsize=(15, 10), layout=(len(numerical_columns)//3 + 1, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count plots for categorical data\n",
    "for col in categorical_columns:\n",
    "    sns.countplot(y=col, data=df)\n",
    "    plt.show()"
   ],
   "id": "2bc1419493f0bfb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4. Correlation Matrix\n",
    "# Select only numeric columns for correlation matrix\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix of Numeric Features\")\n",
    "plt.show()"
   ],
   "id": "628b48bd7c355862",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5. Feature Engineering Insights\n",
    "print(\"\\nUnique Values per Column:\")\n",
    "print(df.nunique())"
   ],
   "id": "fe3cdaddebf9b3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Strip any leading/trailing spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Calculate the number of missing values for each feature\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Output the count of missing values for each feature\n",
    "print(\"Missing values per feature:\")\n",
    "for feature, missing_count in missing_values.items():\n",
    "    print(f\"{feature}: {missing_count}\")"
   ],
   "id": "5c440720cb4ac4fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the KNN imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "\n",
    "# Apply KNN imputer to the DataFrame\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "df[numerical_columns] = knn_imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Check if all null values are imputed\n",
    "foundNull = df.isnull().values.any()\n",
    "if foundNull:\n",
    "    raise TypeError('Found null value in DataFrame.')\n",
    "\n",
    "# Output the cleaned DataFrame\n",
    "print(\"DataFrame after KNN imputation:\")\n",
    "print(df)"
   ],
   "id": "95045ed7f537819a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select numerical columns\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "df_numerical = df[numerical_columns]\n",
    "\n",
    "# Create a copy of the original data\n",
    "original_data = df_numerical.copy()\n",
    "\n",
    "# Introduce missing values artificially (10% missing)\n",
    "np.random.seed(42)\n",
    "mask = np.random.rand(*df_numerical.shape) < 0.1  # Mask for 10% missing\n",
    "df_missing = df_numerical.copy()\n",
    "df_missing[mask] = np.nan\n",
    "\n",
    "# Apply KNN Imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
    "df_imputed = pd.DataFrame(knn_imputer.fit_transform(df_missing), columns=numerical_columns)\n",
    "\n",
    "# Compare imputed values with original values\n",
    "print(f\"Mean Squared Error for each feature:\")\n",
    "for col in numerical_columns:\n",
    "    # Calculate error only for artificially missing values\n",
    "    mask_col = mask[:, df_numerical.columns.get_loc(col)]\n",
    "    mse = mean_squared_error(original_data[col][mask_col], df_imputed[col][mask_col])\n",
    "    print(f\"'{col}': {mse}\")"
   ],
   "id": "5c9ac104958c4701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Anomaly Detection\n",
    "Since medical conditions that lead to the rejection of a donor are rare (luckily) and can be very\n",
    "versatile. It is near impossible to categorize every possible condition. Hence, it would be useful to have an anomaly\n",
    "detection algorithm in place as a safety mechanism to detect suspicious blood samples for further testing.\n",
    "- Train an anomaly detection model based only on valid blood donors without a medical condition.\n",
    "- Evaluate the accuracy of your anomaly detection by testing it also on donors with a medical condition.\n",
    "- Perform a PCA to visualize the true / false positive and true / false negative predictions as well as the decision\n",
    "boundary of your anomaly detection. How much variance is explained by the first two main components? "
   ],
   "id": "d7f9fd9a8724a94b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Filter data for valid blood donors\n",
    "donors = df[df['Category'] == '0=Blood Donor']\n",
    "\n",
    "# Filter data for non-donors (anomalous category)\n",
    "non_donors = df[df['Category'] != '0=Blood Donor']\n",
    "\n",
    "# Numerical columns for modeling\n",
    "numerical_columns = ['ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n",
    "\n",
    "# Features for anomaly detection\n",
    "X_train_valid, X_test_valid = train_test_split(donors[numerical_columns], test_size=0.2, random_state=42) # Train only on valid donors\n",
    "X_test = non_donors[numerical_columns]  # Use non-donors for testing\n",
    "\n",
    "# Define and train Isolation Forest\n",
    "iso_forest = IsolationForest(random_state=42, contamination=0.1)  # Assuming 10% contamination\n",
    "iso_forest.fit(X_train_valid)\n",
    "\n",
    "# Predict anomalies on the combined dataset\n",
    "X_test_valid_with_labels = donors.loc[X_test_valid.index]\n",
    "X_test_with_labels = non_donors.loc[X_test.index]\n",
    "combined_data = pd.concat([X_test_valid_with_labels, X_test_with_labels], axis=0)\n",
    "combined_features = combined_data[numerical_columns]\n",
    "predictions = iso_forest.predict(combined_features)\n",
    "\n",
    "# Map predictions to binary format (1: normal, -1: anomaly)\n",
    "pred_binary = np.where(predictions == 1, 1, 0)  # 1: Valid, 0: Anomaly\n",
    "true_labels = np.where(combined_data['Category'] == '0=Blood Donor', 1, -1)\n",
    "true_binary = np.where(true_labels == 1, 1, 0)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_binary, pred_binary, target_names=['Anomaly', 'Valid']))\n",
    "\n",
    "# Calculate the counts of true/false positives and negatives\n",
    "tp = np.sum((true_binary == 1) & (pred_binary == 1))  # True Positives\n",
    "fp = np.sum((true_binary == 0) & (pred_binary == 1))  # False Positives\n",
    "tn = np.sum((true_binary == 0) & (pred_binary == 0))  # True Negatives\n",
    "fn = np.sum((true_binary == 1) & (pred_binary == 0))  # False Negatives\n",
    "\n",
    "# Display the counts\n",
    "print(f\"Counts:\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(combined_features)\n",
    "\n",
    "# Variance explained by PCA components\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "print(f\"Variance explained by the first two components: {variance_explained}\")\n",
    "\n",
    "# Scatter plot with True/False Positives and Negatives\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(pca_data[(true_binary == 1) & (pred_binary == 1), 0], pca_data[(true_binary == 1) & (pred_binary == 1), 1], \n",
    "            c='green', label='True Positives', alpha=0.6, edgecolor='k')\n",
    "plt.scatter(pca_data[(true_binary == 0) & (pred_binary == 1), 0], pca_data[(true_binary == 0) & (pred_binary == 1), 1], \n",
    "            c='orange', label='False Positives', alpha=0.6, edgecolor='k')\n",
    "plt.scatter(pca_data[(true_binary == 0) & (pred_binary == 0), 0], pca_data[(true_binary == 0) & (pred_binary == 0), 1], \n",
    "            c='blue', label='True Negatives', alpha=0.6, edgecolor='k')\n",
    "plt.scatter(pca_data[(true_binary == 1) & (pred_binary == 0), 0], pca_data[(true_binary == 1) & (pred_binary == 0), 1], \n",
    "            c='red', label='False Negatives', alpha=0.6, edgecolor='k')\n",
    "plt.title(\"PCA Visualization of Predictions\")\n",
    "plt.xlabel(f\"Principal Component 1 ({variance_explained[0]:.2%} variance)\")\n",
    "plt.ylabel(f\"Principal Component 2 ({variance_explained[1]:.2%} variance)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Decision boundary visualization using PCA components\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(pca_data[:, 0].min() - 1, pca_data[:, 0].max() + 1, 100),\n",
    "    np.linspace(pca_data[:, 1].min() - 1, pca_data[:, 1].max() + 1, 100)\n",
    ")\n",
    "# Prepare the grid points for prediction\n",
    "mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "inverse_transformed = pca.inverse_transform(mesh_points)\n",
    "\n",
    "# Ensure the mesh_points (inverse_transformed) have valid feature names\n",
    "inverse_transformed_df = pd.DataFrame(inverse_transformed, columns=numerical_columns)\n",
    "\n",
    "# Predict anomaly scores for the mesh points\n",
    "mesh_scores = iso_forest.decision_function(inverse_transformed_df).reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.contourf(xx, yy, mesh_scores, levels=50, cmap='coolwarm', alpha=0.5)\n",
    "plt.colorbar(label='Anomaly Score')\n",
    "plt.scatter(pca_data[(true_binary == 1) & (pred_binary == 1), 0], pca_data[(true_binary == 1) & (pred_binary == 1), 1], \n",
    "            c='green', label='True Positives', alpha=0.6, edgecolor='k')\n",
    "plt.scatter(pca_data[(true_binary == 0) & (pred_binary == 1), 0], pca_data[(true_binary == 0) & (pred_binary == 1), 1], \n",
    "            c='orange', label='False Positives', alpha=0.6, edgecolor='k')\n",
    "plt.scatter(pca_data[(true_binary == 0) & (pred_binary == 0), 0], pca_data[(true_binary == 0) & (pred_binary == 0), 1], \n",
    "            c='blue', label='True Negatives', alpha=0.6, edgecolor='k')\n",
    "plt.scatter(pca_data[(true_binary == 1) & (pred_binary == 0), 0], pca_data[(true_binary == 1) & (pred_binary == 0), 1], \n",
    "            c='red', label='False Negatives', alpha=0.6, edgecolor='k')\n",
    "plt.title(\"PCA Visualization with Decision Boundary\")\n",
    "plt.xlabel(f\"Principal Component 1 ({variance_explained[0]:.2%} variance)\")\n",
    "plt.ylabel(f\"Principal Component 2 ({variance_explained[1]:.2%} variance)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "cc415f1b050c363a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Explainable Model\n",
    "For your decision support your model should be explainable. Train a model with a focus on\n",
    "explainability with an as simple as possible structure while still maintaining its predictive power.\n",
    "- Train a decision tree classifier on the imputed data. Evaluate your model’s accuracy and visualize the tree structure to\n",
    "help the hospital personal understand the decision process. Each inference should not only put out the class, but also\n",
    "the decision path taken. Make the tree as simple and understandable as possible."
   ],
   "id": "aa5c964496020d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import find\n",
    "\n",
    "# Prepare features and target\n",
    "# Include Age, Sex, and numerical columns\n",
    "numerical_columns = ['ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n",
    "features = ['Age', 'Sex'] + numerical_columns\n",
    "\n",
    "# Encode 'Sex'\n",
    "if df['Sex'].dtype == 'object':\n",
    "    df['Sex'] = df['Sex'].map({'m': 0, 'f': 1})  # Example encoding: 0 for male, 1 for female\n",
    "\n",
    "# Target: 'Category' (1 for valid, 0 for invalid)\n",
    "df['Target'] = (df['Category'] == '0=Blood Donor').astype(int)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=4, random_state=42)  # Adjust max_depth for simplicity\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Invalid', 'Valid']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Invalid', 'Valid']).plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize Decision Tree\n",
    "plt.figure(figsize=(16, 10))\n",
    "plot_tree(\n",
    "    dt_classifier,\n",
    "    feature_names=features,\n",
    "    class_names=['Invalid', 'Valid'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()\n",
    "\n",
    "# Extract decision paths for explainability\n",
    "print(\"Decision Tree Rules:\")\n",
    "tree_rules = export_text(dt_classifier, feature_names=features)\n",
    "print(tree_rules)\n",
    "\n",
    "# Example of explaining individual predictions\n",
    "print(\"\\nExample Predictions and Decision Paths:\")\n",
    "for i in range(5):  # Show decision paths for the first 5 samples in the test set\n",
    "    sample = X_test.iloc[[i]]  # Keep it as a DataFrame with proper column names\n",
    "    path = dt_classifier.decision_path(sample)  # Use the correct input format\n",
    "    print(f\"\\nSample {i+1}: {sample}\")\n",
    "    \n",
    "    # Decode decision path\n",
    "    node_indices = find(path)[1]  # Extract nodes from the sparse matrix\n",
    "    print(\"Decision Path (Node Indices):\", node_indices)\n",
    "\n"
   ],
   "id": "f8f169f92c70d7c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. High Performance Model\n",
    "This time the focus is on predictive power. Try and train a more accurate model. Is it worth\n",
    "the effort?\n",
    "- Train and optimize an XGBoost classifier on the imputed data.\n",
    "- Use SHAP local explanation techniques on 5 selected data points and discuss the results\n",
    "- Use SHAP global explanation techniques to visualize and discuss the influence of different features.\n",
    "- Evaluate the XGBoost’s accuracy and compare it to the Decision Tree"
   ],
   "id": "cb3afb52034965f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Features and target\n",
    "X = df[features]  \n",
    "y = df['Target']  \n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define XGBoost Classifier\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Hyperparameter optimization (example grid)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "print(\"Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Invalid', 'Valid']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Invalid', 'Valid']).plot(cmap='Blues')\n",
    "plt.title(\"XGBoost Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ],
   "id": "bf12497641e62b54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.Explainer(best_xgb)\n",
    "\n",
    "# Select 5 random test samples for explanation\n",
    "sample_indices = X_test.sample(5, random_state=42).index\n",
    "sample_data = X_test.loc[sample_indices]\n",
    "\n",
    "# Explain predictions\n",
    "shap_values = explainer(sample_data)\n",
    "\n",
    "# Visualize SHAP explanations for each selected data point\n",
    "for i, index in enumerate(sample_indices):\n",
    "    print(f\"SHAP explanation for test sample {i + 1}:\")\n",
    "    shap.waterfall_plot(shap_values[i])"
   ],
   "id": "deb981cdb05ad270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute SHAP values for the entire test set\n",
    "shap_values_global = explainer(X_test)  \n",
    "\n",
    "# Global summary plot\n",
    "shap.summary_plot(shap_values_global, X_test)\n",
    "\n",
    "# Bar plot for mean absolute SHAP values\n",
    "shap.summary_plot(shap_values_global, X_test, plot_type=\"bar\")"
   ],
   "id": "c3a0f72a34f4852e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Combined Model\n",
    "Put all components into a single model artifact for deployment such that clinic personal has all important\n",
    "information at hand to make an informed decision.\n",
    "- Combine the XGBoost, Decision Tree and Anomaly Detection in a single model class including all necessary methods (fit,\n",
    "predict…). The Decision Tree provides an explainable assistance for the hospital personal and the XGBoost (probably) a more\n",
    "accurate classification. The Anomaly Detection increases the robustness of the model for conditions that have not been\n",
    "explicitly trained or for human errors. Generate a few test anomalies to check your detection.\n",
    "- Evaluate, discuss and plot the performance of your combined model."
   ],
   "id": "ae4e4bb54a7a19c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "class CombinedModel:\n",
    "    def __init__(self):\n",
    "        # Initialize models\n",
    "        self.xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "        self.decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "        self.anomaly_detector = IsolationForest(random_state=42)\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the XGBoost, Decision Tree, and Anomaly Detection models.\n",
    "        \"\"\"\n",
    "        print(\"Fitting XGBoost...\")\n",
    "        self.xgb.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Fitting Decision Tree...\")\n",
    "        self.decision_tree.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Fitting Anomaly Detector...\")\n",
    "        self.anomaly_detector.fit(X_train)  # Fit Isolation Forest only on features\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the combined model.\n",
    "        \"\"\"\n",
    "        # Step 1: Anomaly Detection\n",
    "        anomalies = self.anomaly_detector.predict(X)  # -1 indicates anomaly, 1 indicates normal\n",
    "        \n",
    "        # Step 2: Decision Tree Prediction (for interpretation)\n",
    "        dt_preds = self.decision_tree.predict(X)\n",
    "        \n",
    "        # Step 3: XGBoost Prediction (for accuracy)\n",
    "        xgb_preds = self.xgb.predict(X)\n",
    "        \n",
    "        # Step 4: Combine results\n",
    "        combined_preds = []\n",
    "        for i, anomaly in enumerate(anomalies):\n",
    "            if anomaly == -1:\n",
    "                combined_preds.append(\"Anomaly\")\n",
    "            else:\n",
    "                combined_preds.append(xgb_preds[i])\n",
    "        \n",
    "        return combined_preds, dt_preds  # Return XGBoost predictions and Decision Tree predictions separately\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the combined model.\n",
    "        \"\"\"\n",
    "        combined_preds, dt_preds = self.predict(X_test)\n",
    "        \n",
    "        # Exclude anomalies for evaluation\n",
    "        normal_indices = [i for i, pred in enumerate(combined_preds) if pred != \"Anomaly\"]\n",
    "        filtered_preds = [combined_preds[i] for i in normal_indices]\n",
    "        filtered_y_test = y_test.iloc[normal_indices]\n",
    "        \n",
    "        print(\"Evaluation for Normal Predictions:\")\n",
    "        print(classification_report(filtered_y_test, filtered_preds))\n",
    "        \n",
    "        print(\"Confusion Matrix for Normal Predictions:\")\n",
    "        print(confusion_matrix(filtered_y_test, filtered_preds))\n",
    "    \n",
    "    def detect_anomalies(self, X):\n",
    "        \"\"\"\n",
    "        Detect anomalies in the data.\n",
    "        \"\"\"\n",
    "        anomaly_predictions = self.anomaly_detector.predict(X)\n",
    "        anomalies = np.where(anomaly_predictions == -1)[0]  # Index of anomalies\n",
    "        print(f\"Detected {len(anomalies)} anomalies.\")\n",
    "        return anomalies\n"
   ],
   "id": "6aa0fc87d41c2136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = CombinedModel()\n",
    "model.fit(X_train, y_train)"
   ],
   "id": "58311bf370ab7490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predictions, dt_interpretations = model.predict(X_test)",
   "id": "66f833320055392a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.evaluate(X_test, y_test)",
   "id": "9682ba86ee97df16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "anomalies = model.detect_anomalies(X_test)",
   "id": "d2c86b3a69c49cc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create anomalies by adding random noise\n",
    "def generate_anomalies(X, n_samples=10, noise_level=10):\n",
    "    np.random.seed(42)\n",
    "    anomalies = X.sample(n=n_samples).copy()\n",
    "    for col in X.columns:\n",
    "        anomalies[col] += np.random.uniform(-noise_level, noise_level, size=n_samples)\n",
    "    return anomalies\n",
    "\n",
    "# Add anomalies to test the detection\n",
    "X_test_anomalies = generate_anomalies(X_test, n_samples=10)\n",
    "anomalies_detected = model.detect_anomalies(X_test_anomalies)"
   ],
   "id": "975cab18bf5c6820",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
